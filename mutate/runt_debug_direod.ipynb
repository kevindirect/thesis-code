{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Runt Transform 'direod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_fct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2bc86c995343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdf_getters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_subsetters2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcs2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_runt_dir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_trfs_dir_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunt_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfill_defaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_variants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_row_mask_keychain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_desc_pfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_runt_entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/crunch/mutate/runt_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaussian_breakpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_breakpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sym_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolize_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfracdiff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDOWN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIDEWAYS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastbreak_eod_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastbreak_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastbreak_confidence_fct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\"\"\" ********** APPLY FUNCTIONS ********** \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/crunch/mutate/label_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mmake_sw_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"exact\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"startswith\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"endswith\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"regex\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exclude\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mgen_label_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_fct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlab_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlab_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlab_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0masset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_fct' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import sep\n",
    "from os.path import dirname, realpath\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "def get_cwd(fname, subdir, crunch_dir=realpath(Path.home()) +sep +'crunch' +sep):\n",
    "    \"\"\"\n",
    "    Convenience function to make a directory string for the current file based on inputs.\n",
    "    Jupyter Notebook in Anaconda invokes the Python interpreter in Anaconda's subdirectory\n",
    "    which is why changing sys.argv[0] is necessary. In the future a better way to do this\n",
    "    should be preferred..\n",
    "    \"\"\"\n",
    "    return crunch_dir +subdir +fname\n",
    "    \n",
    "def fix_path(cwd):\n",
    "    \"\"\"\n",
    "    Convenience function to fix argv and python path so that jupyter notebook can run the same as\n",
    "    any script in crunch.\n",
    "    \"\"\"\n",
    "    sys.argv[0] = cwd\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "fix_path(get_cwd('test.ipynb', 'recon' +sep))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, vectorize\n",
    "from dask import delayed, dataframe as dd\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from common_util import MUTATE_DIR, DT_HOURLY_FREQ, DT_CAL_DAILY_FREQ\n",
    "from common_util import load_json, dump_json, remove_dups_list, list_get_dict, is_empty_df, search_df, benchmark\n",
    "from data.data_api import DataAPI\n",
    "from data.access_util import df_getters as dg, col_subsetters2 as cs2\n",
    "from mutate.common import default_runt_dir_name, default_trfs_dir_name\n",
    "from mutate.runt_util import *\n",
    "from mutate.runt import fill_defaults, get_variants, get_row_mask_keychain, get_desc_pfx, make_runt_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Logging Level and Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "date_range = {\n",
    "    'id': ('lt', 2018)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Runt and Transform Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runt_dir_name = default_runt_dir_name\n",
    "trfs_dir_name = default_trfs_dir_name\n",
    "\n",
    "runt_dir = MUTATE_DIR +runt_dir_name\n",
    "trfs_dir = runt_dir +trfs_dir_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_defaults = load_json('trf_defaults.json', dir_path=runt_dir)\n",
    "graph = load_json('graph.json', dir_path=runt_dir)\n",
    "trfs = {}\n",
    "\n",
    "logging.info('loading step settings...')\n",
    "for fname in os.listdir(trfs_dir):\n",
    "    trf = load_json(fname, dir_path=trfs_dir)\n",
    "    trfs[trf['meta']['name']] = trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Test Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(step_info, date_range, overwrites = {}):\n",
    "    meta, fn, var, rm, src, dst = step_info['meta'], step_info['fn'], step_info['var'], step_info['rm'], step_info['src'], step_info['dst']\n",
    "\n",
    "    # Loading transform, apply, and frequency settings\n",
    "    ser_fn = overwrites['ser_fn'] if ('ser_fn' in overwrites) else RUNT_FN_TRANSLATOR[fn['ser_fn']]\n",
    "    rtype_fn = overwrites['df_fn'] if ('df_fn' in overwrites) else RUNT_TYPE_TRANSLATOR[fn['df_fn']]\n",
    "    freq = overwrites['freq'] if ('freq' in overwrites) else RUNT_FREQ_TRANSLATOR[fn['freq']]\n",
    "    res_freq = RUNT_FREQ_TRANSLATOR[meta['res_freq']]\n",
    "\n",
    "    # Making all possible parameter combinations\n",
    "    variants = get_variants(var, meta['var_fmt'])\n",
    "\n",
    "    # Loading row mask, if any\n",
    "    if (rm is not None):\n",
    "        rm_dg, rm_cs = list_get_dict(dg, rm), list_get_dict(cs2, rm)\n",
    "        rm_paths, rm_recs, rm_dfs = DataAPI.load_from_dg(rm_dg, rm_cs)\n",
    "        rm_keys = [remove_dups_list([key_chain[i] for key_chain in rm_paths]) for i in range(len(rm_paths[0]))]\n",
    "\n",
    "    # Loading input data\n",
    "    src_dg, src_cs = list_get_dict(dg, src), list_get_dict(cs2, src)\n",
    "    src_paths, src_recs, src_dfs = DataAPI.load_from_dg(src_dg, src_cs)\n",
    "    logging.debug('src_paths[0] ' +str(src_paths[0]))\n",
    "    logging.debug('src_paths[-1] ' +str(src_paths[-1]))\n",
    "\n",
    "    # Run transforms on inputs\n",
    "    for key_chain in src_paths:\n",
    "        logging.info('data: ' +str('_'.join(key_chain)))\n",
    "        src_rec, src_df = list_get_dict(src_recs, key_chain), list_get_dict(src_dfs, key_chain)\n",
    "        src_df = src_df.loc[search_df(src_df, date_range), :].dropna(axis=0, how='all')\n",
    "\n",
    "        # Masking rows in src from row mask\n",
    "        if (rm is not None):\n",
    "            rm_key_chain = get_row_mask_keychain(key_chain, rm_keys)\n",
    "            rm_df = list_get_dict(rm_dfs, rm_key_chain).dropna()\n",
    "            not_in_src = rm_df.index.difference(src_df.index)\n",
    "            logging.debug('row mask: ' +str('_'.join(rm_key_chain)))\n",
    "            if (len(not_in_src)>0):\n",
    "                logging.debug('rm_idx - src_idx: ' +str(not_in_src))\n",
    "                src_df = src_df.loc[src_df.index & rm_df.index, :].dropna(axis=0, how='all')\n",
    "            else:\n",
    "                src_df = src_df.loc[rm_df.index, :].dropna(axis=0, how='all')\n",
    "\n",
    "        logging.debug('pre_transform: ' +str(src_df))\n",
    "\n",
    "        # Running variants of the transform\n",
    "        for variant in variants:\n",
    "            fn = ser_fn(**variant)\n",
    "            runted_df = rtype_fn(src_df, ser_fn(**variant), freq)\n",
    "            desc_sfx = meta['rec_fmt'].format(**variant)\n",
    "            desc_pfx = get_desc_pfx(key_chain, src_rec)\n",
    "            desc = '_'.join([desc_pfx, desc_sfx])\n",
    "\n",
    "            if (meta['mtype_from']=='name'):       mutate_type = meta['name']\n",
    "            elif (meta['mtype_from']=='rec_fmt'):  mutate_type = desc_sfx\n",
    "\n",
    "            assert(not is_empty_df(runted_df))\n",
    "            entry = make_runt_entry(desc, res_freq, mutate_type, src_rec)\n",
    "            logging.info('dumping ' +desc +'...')\n",
    "            logging.debug('post_transform: ' +str(runted_df))\n",
    "            yield entry, runted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Transform\n",
    "Fill it in (default is day moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_name = 'direod'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = trfs[trf_name]\n",
    "step = fill_defaults(trf, trf_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for runt_rec, runt_df in test_step(step, date_range):\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Disk Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = ['dir', 'direod']\n",
    "actual_dg, actual_cs = list_get_dict(dg, au), list_get_dict(cs2, au)\n",
    "actual_paths, actual_recs, actual_dfs = DataAPI.load_from_dg(actual_dg, actual_cs)\n",
    "logging.debug('actual_paths[0] ' +str(actual_paths[0]))\n",
    "logging.debug('actual_paths[-1] ' +str(actual_paths[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_chain in actual_paths:\n",
    "    actual_rec, actual_df = list_get_dict(actual_recs, key_chain), list_get_dict(actual_dfs, key_chain)\n",
    "    logging.debug(str(key_chain))\n",
    "    logging.debug(actual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
