{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import sep\n",
    "from os.path import dirname, realpath\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import logging\n",
    "\n",
    "def get_cwd(fname, subdir, crunch_dir=realpath(Path.home()) +sep +'crunch' +sep):\n",
    "    \"\"\"\n",
    "    Convenience function to make a directory string for the current file based on inputs.\n",
    "    Jupyter Notebook in Anaconda invokes the Python interpreter in Anaconda's subdirectory\n",
    "    which sis why changing sys.argv[0] is necessary. In the future a better way to do this\n",
    "    should be preferred..\n",
    "    \"\"\"\n",
    "    return crunch_dir +subdir +fname\n",
    "\n",
    "def fix_path(cwd):\n",
    "    \"\"\"\n",
    "    Convenience function to fix argv and python path so that jupyter notebook can run the same as\n",
    "    any script in crunch.\n",
    "    \"\"\"\n",
    "    sys.argv[0] = cwd\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "fix_path(get_cwd('pattern_eda.ipynb', 'mutate' +sep))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, vectorize, float64, uint\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.piecewise import PiecewiseAggregateApproximation\n",
    "from tslearn.piecewise import SymbolicAggregateApproximation, OneD_SymbolicAggregateApproximation\n",
    "from scipy.stats import zscore\n",
    "from sortedcontainers import SortedList, SortedSet \n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from common_util import DT_HOURLY_FREQ, DT_CAL_DAILY_FREQ, DT_BIZ_DAILY_FREQ, get_custom_biz_freq, get_custom_biz_freq_df, query_df, search_df, chained_filter, benchmark\n",
    "from common_util import MUTATE_DIR, load_json, outer_join, left_join, count_nn_df, count_nz_df, count_nn_nz_df, pairwise, cust_count, dti_to_ymd\n",
    "from data.data_api import DataAPI\n",
    "from data.access_util import col_subsetters as cs\n",
    "from mutate.common import dum\n",
    "from recon.viz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = {\n",
    "    'id': ('lt', 2018)\n",
    "}\n",
    "search_terms = {\n",
    "    'stage': 'mutate',\n",
    "    'mutate_type': 'normalize',\n",
    "    'raw_cat': 'us_equity_index'\n",
    "}\n",
    "normalize_dfs = defaultdict(dict)\n",
    "for rec, norm_df in DataAPI.generate(search_terms):\n",
    "    normalize_dfs[rec.root][rec.desc] = norm_df.loc[search_df(norm_df, date_range)]\n",
    "logging.info('normalize data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_dfs = normalize_dfs['sp_500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_value(ser, capture=.80):\n",
    "    tups = list(ser.iteritems())\n",
    "    proportion = 0.0\n",
    "\n",
    "    for idx, val in sorted(tups, key=lambda tup: tup[0], reverse=True):\n",
    "        print(idx)\n",
    "        if (proportion > capture):\n",
    "            return {ser.max():ser.idxmax(), proportion: idx}\n",
    "        else:\n",
    "            proportion += val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_pba_dzn\n",
      "9\n",
      "8\n",
      "7\n",
      "{0.9375: 8, 0.9424846625766872: 7}\n",
      "raw_pba_dmx\n",
      "9\n",
      "8\n",
      "7\n",
      "{0.9375: 8, 0.9424846625766872: 7}\n",
      "raw_vol_dzn\n",
      "14\n",
      "13\n",
      "11\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "{0.5954754601226994: 8, 0.9419095092024539: 6}\n",
      "raw_vol_dmx\n",
      "14\n",
      "13\n",
      "11\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "{0.5954754601226994: 8, 0.9419095092024539: 6}\n"
     ]
    }
   ],
   "source": [
    "for key, norm_df in normed_dfs.items():\n",
    "    if (key[:6]!='thresh'):\n",
    "        print(key)\n",
    "        cust, count_df = cust_count(norm_df)\n",
    "        vc = count_df.apply(pd.Series.value_counts, normalize=True)\n",
    "        most_common = vc.idxmax(axis=0)\n",
    "#         print(vc)\n",
    "        seq = get_seq_value(vc.iloc[:, 0])\n",
    "        print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
