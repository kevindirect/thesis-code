{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Group Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import sep\n",
    "from os.path import dirname, realpath\n",
    "from pathlib import Path\n",
    "from functools import partial, reduce\n",
    "import logging\n",
    "\n",
    "def get_cwd(fname, subdir, crunch_dir=realpath(Path.home()) +sep +'crunch' +sep):\n",
    "    \"\"\"\n",
    "    Convenience function to make a directory string for the current file based on inputs.\n",
    "    Jupyter Notebook in Anaconda invokes the Python interpreter in Anaconda's subdirectory\n",
    "    which is why changing sys.argv[0] is necessary. In the future a better way to do this\n",
    "    should be preferred..\n",
    "    \"\"\"\n",
    "    return crunch_dir +subdir +fname\n",
    "\n",
    "def fix_path(cwd):\n",
    "    \"\"\"\n",
    "    Convenience function to fix argv and python path so that jupyter notebook can run the same as\n",
    "    any script in crunch.\n",
    "    \"\"\"\n",
    "    sys.argv[0] = cwd\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "fname = 'dataload_test.ipynb'   # FILL\n",
    "dir_name = 'model'              # FILL\n",
    "fix_path(get_cwd(fname, dir_name +sep))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import delayed, compute\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from common_util import RECON_DIR, JSON_SFX_LEN, DT_CAL_DAILY_FREQ, is_type, pd_common_idx_rows, remove_dups_list, set_loglevel, chained_filter, get_variants, dump_df, load_json, gb_transpose, pd_common_index_rows, filter_cols_below, inner_join, outer_join, ser_shift, list_get_dict, window_iter, benchmark\n",
    "from common_util import str_to_list, isnt, np_inner, get_class_name, get0, midx_get_level, midx_intersect, pd_common_idx_rows, midx_split, pd_midx_to_arr, window_iter, np_is_ndim\n",
    "from model.common import XG_DIR, EXPECTED_NUM_HOURS, default_xg\n",
    "from model.data_util import xgdg, align_first_last_cols, prune_nulls\n",
    "from model.model_util import CLF_MAP\n",
    "from data.data_api import DataAPI\n",
    "from data.access_util import df_getters as dg, col_subsetters2 as cs2\n",
    "from recon.dataset_util import prep_dataset, gen_group\n",
    "from recon.split_util import get_train_test_split, gen_time_series_split, index_three_split, pd_binary_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this script to test if a particlar xgdg works with a particular model\n",
    "* Use xgdg_dataload_test notebook before using this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_loglevel('info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_xg0_single_channel_daily.json',\n",
       " 'test_xg1_multi_channel_daily.json',\n",
       " 'test_xg2_single_channel_intraday.json',\n",
       " 'test_xg3_multi_channel_intraday.json',\n",
       " 'xg0_reteod_direod.json']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(XG_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = None\n",
    "cmd_input = {\n",
    "    'model=': 'TCN',\n",
    "    'backend=': 'pytorch',\n",
    "    'xg=': 'test_xg0_single_channel_daily.json',\n",
    "    'assets=': 'sp_500',\n",
    "    'trials_count=': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code = cmd_input['model='] if (cmd_input['model='] is not None) else default_model\n",
    "backend_name = cmd_input['backend='] if (cmd_input['backend='] is not None) else default_backend\n",
    "xg_fname = cmd_input['xg='] if (cmd_input['xg='] is not None) else default_xg\n",
    "assets = str_to_list(cmd_input['assets=']) if (cmd_input['assets='] is not None) else None\n",
    "trials_count = int(cmd_input['trials_count=']) if (cmd_input['trials_count='] is not None) else default_trials_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda') if (torch.cuda.is_available()) else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:model: TCN_CLF\n",
      "INFO:root:backend: pytorch\n",
      "INFO:root:xg: test_xg0_single_channel_daily\n",
      "INFO:root:assets: sp_500\n"
     ]
    }
   ],
   "source": [
    "mod_obj = CLF_MAP[backend_name][model_code]()\n",
    "mod_name = get_class_name(mod_obj)\n",
    "xg_name = xg_fname.rstrip('.json')\n",
    "\n",
    "logging.info('model: {}'.format(mod_name))\n",
    "logging.info('backend: {}'.format(backend_name))\n",
    "logging.info('xg: {}'.format(xg_name))\n",
    "logging.info('assets: {}'.format(str('all' if (assets==None) else ', '.join(assets))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:(X, y, z) -> (raw_pba_oc_retxeod_reteod[:], raw_pba_oc_retxeod_direod[:], raw_pba_oc_retxeod_reteod[:])\n"
     ]
    }
   ],
   "source": [
    "for i, (paths, recs, dfs) in enumerate(xgdg(xg_fname, delayed=True, assets=assets, filters_map=None)):\n",
    "    fpath, lpath, tpath = paths\n",
    "    frec, lrec, trec = recs\n",
    "    logging.info('(X, y, z) -> ({fdesc}[:], {ldesc}[:], {tdesc}[:])'.format(fdesc=frec.desc, ldesc=lrec.desc, tdesc=trec.desc))\n",
    "    f, l, t = dfs.compute()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_l, neg_l = pd_binary_clip(l)\n",
    "l = pos_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = .2\n",
    "test_ratio = .2\n",
    "train_ratio = 1-(val_ratio+test_ratio)\n",
    "f_train_idx, f_val_idx, f_test_idx = midx_split(f.index, train_ratio, val_ratio, test_ratio)\n",
    "l_train_idx, l_val_idx, l_test_idx = midx_split(l.index, train_ratio, val_ratio, test_ratio)\n",
    "t_train_idx, t_val_idx, t_test_idx = midx_split(t.index, train_ratio, val_ratio, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_pd, f_val_pd, f_test_pd = f.loc[f_train_idx], f.loc[f_val_idx], f.loc[f_test_idx]\n",
    "l_train_pd, l_val_pd, l_test_pd = l.loc[l_train_idx], l.loc[l_val_idx], l.loc[l_test_idx]\n",
    "t_train_pd, t_val_pd, t_test_pd = t.loc[t_train_idx], t.loc[t_val_idx], t.loc[t_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (is_type(f.index, pd.core.index.MultiIndex)):\n",
    "    f_train_np, f_val_np, f_test_np = map(pd_midx_to_arr, [f_train_pd.stack(), f_val_pd.stack(), f_test_pd.stack()])\n",
    "else:\n",
    "    f_train_np, f_val_np, f_test_np = f_train_pd.values, f_val_pd.values, f_test_pd.values\n",
    "l_train_np, l_val_np, l_test_np = l_train_pd.values, l_val_pd.values, l_test_pd.values\n",
    "t_train_np, t_val_np, t_test_np = t_train_pd.values, t_val_pd.values, t_test_pd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val_tc = torch.tensor(t_val_np, dtype=torch.float32, device=dev, requires_grad=False).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Observation Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3007, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "obs_shape = mod_obj.get_obs_shape(f_train_np.shape)\n",
    "print(f_train_np.shape)\n",
    "print(obs_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': <hyperopt.pyll.base.Apply at 0x7f6463759860>,\n",
       " 'batch_size': <hyperopt.pyll.base.Apply at 0x7f6463759908>,\n",
       " 'loss': <hyperopt.pyll.base.Apply at 0x7f6463759358>,\n",
       " 'opt': <hyperopt.pyll.base.Apply at 0x7f64637595f8>,\n",
       " 'input_windows': <hyperopt.pyll.base.Apply at 0x7f64637353c8>,\n",
       " 'topology': <hyperopt.pyll.base.Apply at 0x7f6463735b00>,\n",
       " 'kernel_size': <hyperopt.pyll.base.Apply at 0x7f6463759160>,\n",
       " 'dropout': <hyperopt.pyll.base.Apply at 0x7f64637592b0>,\n",
       " 'attention': False,\n",
       " 'max_attn_len': 120}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_obj.get_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = list(reversed(l_train_pd.value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 500,\n",
    "    'batch_size': 128, #256\n",
    "    'loss': 'nll',\n",
    "    'cw': pmf,\n",
    "    'opt': {\n",
    "        'name': 'Adam',\n",
    "        'lr': .0001\n",
    "    },\n",
    "    'input_windows': 20,\n",
    "    'topology': [100],\n",
    "    'kernel_size': 8,\n",
    "    'dropout': .1,\n",
    "    'attention': False,\n",
    "    'max_attn_len': 80,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (f_train_np, l_train_np)\n",
    "val_data = (f_val_np, l_val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3007, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_train_pd.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2988, 1, 620)\n",
      "(2988, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = mod_obj.preproc(params, train_data)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Batch Loss Compute Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloss(params, model, loss_function, feat_batch, lab_batch, optimizer=None, ret_train_pred=False, metrics_fns=mod_obj.metrics_fns):\n",
    "    \"\"\"\n",
    "    Compute loss and metrics on batch, run optimizer on losses if passed.\n",
    "    \"\"\"\n",
    "    # logging.debug('batch tensor[0][0]: {}'.format(feat_batch[0][0]))\n",
    "    outputs_batch = model(feat_batch)\n",
    "    loss = loss_function(outputs_batch, lab_batch)\n",
    "    max_batch, pred_batch = torch.max(outputs_batch, dim=1) # Convert network outputs into predictions\n",
    "    lab_batch_cpu = lab_batch.cpu()\n",
    "    pred_batch_cpu = pred_batch.cpu()\n",
    "    metrics = {name: fn(lab_batch_cpu, pred_batch_cpu) for name, fn in metrics_fns.items()}\n",
    "\n",
    "    if (optimizer is not None):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (not ret_train_pred):\n",
    "            return loss.item(), len(feat_batch), metrics\n",
    "\n",
    "#     logging.debug('batch loss:   {}'.format(loss.item()))\n",
    "    return loss.item(), len(feat_batch), metrics, (max_batch.exp(), pred_batch.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCN(\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(1, 100, kernel_size=(8,), stride=(1,), padding=(7,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(8,), stride=(1,), padding=(7,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(1, 100, kernel_size=(8,), stride=(1,), padding=(7,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1)\n",
       "          (4): Conv1d(100, 100, kernel_size=(8,), stride=(1,), padding=(7,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1)\n",
       "        )\n",
       "        (downsample): Conv1d(1, 100, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (logprob): LogSoftmax()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make Model, Loss Fn, and Optimizer\n",
    "mdl = mod_obj.get_model(params, obs_shape).to(device=dev)\n",
    "loss_fn = mod_obj.make_loss_fn(params, None if (isnt(params['cw'])) else torch.tensor(params['cw']).to(dev)).to(dev)\n",
    "opt = mod_obj.make_optimizer(params, mdl.parameters())\n",
    "display(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = self.tbx(params, logdir) if (logdir is not None) else None\n",
    "mdl.zero_grad()\n",
    "opt.zero_grad()\n",
    "\n",
    "# Metrics\n",
    "history = {\n",
    "    'loss': [],\n",
    "    'val_loss': []\n",
    "}\n",
    "for name in mod_obj.metrics_fns.keys():\n",
    "    history[name] = []\n",
    "    history['val_{}'.format(name)] = []\n",
    "\n",
    "# Fit Model\n",
    "try:\n",
    "    for epoch in range(params['epochs']):\n",
    "        epoch_str = str(epoch).zfill(3)\n",
    "\n",
    "        mdl.train()\n",
    "        losses, nums, metrics = zip(*[bloss(params, mdl, loss_fn, Xb, yb, optimizer=opt) for Xb, yb in mod_obj.batchify(params, mod_obj.preproc(params, train_data), dev, shuffle_batches=True)])\n",
    "        loss = np_inner(losses, nums)\n",
    "        soa = {name[0]: tuple(d[name[0]] for d in metrics) for name in zip(*metrics)}\n",
    "        metric = {name: np_inner(vals, nums) for name, vals in soa.items()}\n",
    "        history['loss'].append(loss)\n",
    "        for name, val in metric.items():\n",
    "            history[name].append(val)\n",
    "\n",
    "        mdl.eval()\n",
    "        with torch.no_grad():\n",
    "            Xe, ye = get0(*mod_obj.batchify(params, mod_obj.preproc(params, val_data), dev, override_batch_size=val_data[-1].size, shuffle_batches=False))\n",
    "            loss, num, metric, pred = bloss(params, mdl, loss_fn, Xe, ye)\n",
    "            pred_conf, pred_dir = pred\n",
    "        history['val_loss'].append(loss)\n",
    "        for name, val in metric.items():\n",
    "            history['val_{}'.format(name)].append(val)\n",
    "\n",
    "    results = {\n",
    "#         'history': history,\n",
    "        'mean': {name: np.mean(vals) for name, vals in history.items()},\n",
    "        'last': {name: vals[-1] for name, vals in history.items()}\n",
    "    }\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error('Error during model fitting: {}'.format(str(e)))\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
