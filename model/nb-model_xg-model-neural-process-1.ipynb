{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb-model_xg-model-neural-process-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import sep\n",
    "from os.path import dirname, realpath\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import logging\n",
    "\n",
    "def get_cwd(fname, subdir, crunch_dir=realpath(Path.home()) +sep +'crunch' +sep):\n",
    "    \"\"\"\n",
    "    Convenience function to make a directory string for the current file based on inputs.\n",
    "    Jupyter Notebook in Anaconda invokes the Python interpreter in Anaconda's subdirectory\n",
    "    which is why changing sys.argv[0] is necessary. In the future a better way to do this\n",
    "    should be preferred..\n",
    "    \"\"\"\n",
    "    return crunch_dir +subdir +fname\n",
    "\n",
    "def fix_path(cwd):\n",
    "    \"\"\"\n",
    "    Convenience function to fix argv and python path so that jupyter notebook can run the same as\n",
    "    any script in crunch.\n",
    "    \"\"\"\n",
    "    sys.argv[0] = cwd\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "fname = 'nb-model_xg-model-neural-process-1.ipynb'\n",
    "dir_name = 'model'\n",
    "fix_path(get_cwd(fname, dir_name +sep))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "from common_util import MODEL_DIR, is_valid, isnt, compose, pd_split_ternary_to_binary, df_del_midx_level, midx_intersect, pd_get_midx_level, pd_rows, df_midx_restack\n",
    "from model.common import DATASET_DIR, XG_PROCESS_DIR, XG_DATA_DIR, XG_DIR, PYTORCH_MODELS_DIR, TEST_RATIO, VAL_RATIO, EXPECTED_NUM_HOURS, default_dataset\n",
    "from model.xg_util import get_xg_feature_dfs, get_xg_label_target_dfs, get_hardcoded_daily_dfs, get_hardcoded_hourly_dfs\n",
    "from model.np_util import AttentiveNP\n",
    "from model.pl_np import NP\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "%autoreload 1\n",
    "%aimport model.np_util, model.pl_np, model.pl_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune the xg data down to the data of interest to use in further experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = ['sp_500', 'russell_2000', 'nasdaq_100', 'dow_jones']\n",
    "chosen_asset = assets[0]\n",
    "\n",
    "fd = get_xg_feature_dfs(chosen_asset)\n",
    "ld, td = get_xg_label_target_dfs(chosen_asset)\n",
    "\n",
    "# daily data axefiles\n",
    "d_all_common = ['dwrmx', 'dwrod', 'dwrpt', 'dwrzn', 'dffd']\n",
    "d_extra = ['dlogret', 'dohlca', 'ddiff', 'dc', 'dwrxmx']\n",
    "\n",
    "# hourly data axefiles\n",
    "h_all_common = ['hdmx', 'hdod', 'hdpt', 'hdzn']\n",
    "h_extra = ['hdgau', 'hduni', 'hohlca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "d_pba = get_hardcoded_daily_dfs(fd, 'pba')\n",
    "d_vol = get_hardcoded_daily_dfs(fd, 'vol')\n",
    "d_buzz = get_hardcoded_daily_dfs(fd, 'buzz')\n",
    "d_nonbuzz = get_hardcoded_daily_dfs(fd, 'buzz')\n",
    "h_pba = get_hardcoded_hourly_dfs(fd, 'pba')\n",
    "h_vol = get_hardcoded_hourly_dfs(fd, 'vol')\n",
    "h_buzz = get_hardcoded_hourly_dfs(fd, 'buzz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (AR)\n",
    "chosen_f = fd['d']['pba']['dret']['pba_hlh_hdxret_dret']\n",
    "chosen_f = fd['d']['pba']['dret']['pba_hoc_hdxret_dret']\n",
    "#chosen_f = fd['d']['pba']['ddir']['pba_hoc_hdxret_ddir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Features\n",
    "# chosen_f = d_pba\n",
    "chosen_f = fd['d']['pba']['ddir']['pba_hoc_hdxret_ddir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fd['d']['pba']\n",
    "# fd['d']['pba']['dohlca']['pba_dohlca'].unstack().pct_change().dropna().corr()\n",
    "# fd['d']['vol']['dohlca']['vol_dohlca'].unstack().pct_change().dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly Features\n",
    "chosen_f = h_pba\n",
    "chosen_f = fd['h']['pba']['hdmx']['pba_hohlca_hdmx']\n",
    "\n",
    "# # Random 'Features':\n",
    "# chosen_f = pd.DataFrame(np.random.rand(len(chosen_f)), index=chosen_f.index).rename({chosen_f.index.levels[1][0]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Labels/Targets and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict ddir(t)\n",
    "chosen_l = pd_split_ternary_to_binary(ld['hoc']['pba']['ddir'].replace(to_replace=-1, value=0))\n",
    "chosen_t = pd_split_ternary_to_binary(td['hoc']['pba']['dret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict thresholded direction: ddir1(t)\n",
    "# chosen_l_len = len(ld['hoc']['pba']['ddir1_log'].columns)\n",
    "# chosen_l = pd_split_ternary_to_binary(ld['hoc']['pba']['ddir1_log'])\n",
    "# chosen_l = chosen_l.sum(level=0)#+len(chosen_l.columns)\n",
    "# chosen_l = (chosen_l[chosen_l!=0] + chosen_l_len).fillna(0).astype(int)\n",
    "# chosen_l = df_add_midx_level(chosen_l, 'pba_hoc_hdxret1_ddir1', loc=1, name='id1')\n",
    "\n",
    "# chosen_t = pd_split_ternary_to_binary(td['hoc']['pba']['dret1_log']).abs().max(level=0)\n",
    "# chosen_t = df_add_midx_level(chosen_t, 'pba_hoc_hdxret1_dret1', loc=1, name='id1')\n",
    "# #chosen_l = chosen_l.sum(level=0)#+len(chosen_l.columns)\n",
    "# #chosen_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Predict' the present ddir(t-1), (sanity check)\n",
    "chosen_l = pd_split_ternary_to_binary(df_del_midx_level(fd['d']['pba']['ddir']['pba_hoc_hdxret_ddir'].rename(columns={-1:'pba_hoc_hdxret_ddir'}), loc=1).replace(to_replace=-1, value=0).astype(int))\n",
    "chosen_t = pd_split_ternary_to_binary(df_del_midx_level(fd['d']['pba']['dret']['pba_hoc_hdxret_dret'].rename(columns={-1:'pba_hoc_hdxret_dret'}), loc=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Common Indexed Rows (Intersect First Level of MultiIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_interval = ('2009', '2018')\n",
    "common_idx = midx_intersect(pd_get_midx_level(chosen_f), pd_get_midx_level(chosen_l), pd_get_midx_level(chosen_t))\n",
    "common_idx = common_idx[(common_idx > year_interval[0]) & (common_idx < year_interval[1])]\n",
    "feature_df, label_df, target_df = map(compose(partial(pd_rows, idx=common_idx), df_midx_restack), [chosen_f, chosen_l, chosen_t])\n",
    "assert(all(feature_df.index.levels[0]==label_df.index.levels[0]))\n",
    "assert(all(feature_df.index.levels[0]==target_df.index.levels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_params = {\n",
    "\t'window_size': 20,\n",
    "\t'feat_dim': None,\n",
    "\t'train_shuffle': False,    \n",
    "\t'epochs': 50,\n",
    "\t'batch_size': 128,\n",
    "\t'batch_step_size': 64,\n",
    "\t'loss': 'clf',\n",
    "\t'opt': {\n",
    "\t\t'name': 'adam',\n",
    "\t\t'kwargs': {\n",
    "\t\t\t'lr': .001\n",
    "\t\t}\n",
    "\t},\n",
    "\t'sch': {\n",
    "#\t\t'name': 'rpl',\n",
    "#\t\t'kwargs': {\n",
    "#\t\t\t'mode': 'min',\n",
    "#\t\t\t'factor': 0.1,\n",
    "#\t\t\t'patience': 10,\n",
    "#\t\t\t'threshold': 0.0001,\n",
    "#\t\t\t'threshold_mode': 'rel',\n",
    "#\t\t\t'cooldown': 0,\n",
    "#\t\t\t'min_lr': 0\n",
    "#\t\t}\n",
    "\t},\n",
    "\t'num_workers': 0,\n",
    "\t'pin_memory': True\n",
    "}\n",
    "\n",
    "m_params = {\n",
    "    'label_size': 1,\n",
    "    'det_encoder_params': {\n",
    "        'it_params': {\n",
    "            \n",
    "        },\n",
    "        'ct_params': {\n",
    "            \n",
    "        },\n",
    "        'tt_params': {\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'lat_encoder_params': {\n",
    "    },\n",
    "    'decoder_params': {\n",
    "    },\n",
    "    'use_lvar': False,\n",
    "    'context_in_target': False\n",
    "}\n",
    "mdl = NP(AttentiveNP, m_params, t_params, (feature_df, label_df, target_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NP(\n",
       "  (model): AttentiveNP(\n",
       "    (det_encoder): DetEncoder(\n",
       "      (input_encoder): StackedTCN(\n",
       "        (model): Sequential(\n",
       "          (rb_0): ResidualBlock(\n",
       "            (net): Sequential(\n",
       "              (tl_0_0): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(6, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_1): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.5, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_2): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (out_act): ReLU()\n",
       "            (downsample): Conv1d(6, 128, kernel_size=(1,), stride=(1,), padding=(7,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (target_transform): StackedTCN(\n",
       "        (model): Sequential(\n",
       "          (rb_0): ResidualBlock(\n",
       "            (net): Sequential(\n",
       "              (tl_0_0): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(5, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_1): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.5, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_2): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (out_act): ReLU()\n",
       "            (downsample): Conv1d(5, 128, kernel_size=(1,), stride=(1,), padding=(7,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (context_transform): StackedTCN(\n",
       "        (model): Sequential(\n",
       "          (rb_0): ResidualBlock(\n",
       "            (net): Sequential(\n",
       "              (tl_0_0): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(5, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_1): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.5, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_2): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (out_act): ReLU()\n",
       "            (downsample): Conv1d(5, 128, kernel_size=(1,), stride=(1,), padding=(7,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (sa_W): ModuleList(\n",
       "        (0): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (xa_W): ModuleList(\n",
       "        (0): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lat_encoder): LatEncoder(\n",
       "      (input_encoder): StackedTCN(\n",
       "        (model): Sequential(\n",
       "          (rb_0): ResidualBlock(\n",
       "            (net): Sequential(\n",
       "              (tl_0_0): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(6, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_1): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.5, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_2): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (out_act): ReLU()\n",
       "            (downsample): Conv1d(6, 128, kernel_size=(1,), stride=(1,), padding=(7,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (sa_W): ModuleList(\n",
       "        (0): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (map_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mean): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (logvar): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (target_transform): StackedTCN(\n",
       "        (model): Sequential(\n",
       "          (rb_0): ResidualBlock(\n",
       "            (net): Sequential(\n",
       "              (tl_0_0): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(5, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_1): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.5, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_2): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (out_act): ReLU()\n",
       "            (downsample): Conv1d(5, 128, kernel_size=(1,), stride=(1,), padding=(7,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): StackedTCN(\n",
       "        (model): Sequential(\n",
       "          (rb_0): ResidualBlock(\n",
       "            (net): Sequential(\n",
       "              (tl_0_0): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_1): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.5, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (tl_0_2): TemporalLayer1d(\n",
       "                (layer): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "                  (1): ELU(alpha=1.0)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (out_act): ReLU()\n",
       "            (downsample): Conv1d(512, 128, kernel_size=(1,), stride=(1,), padding=(7,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (alpha): Linear(in_features=24064, out_features=1, bias=True)\n",
       "      (beta): Linear(in_features=24064, out_features=1, bias=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "INFO:lightning:Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "escb = EarlyStopping(monitor='val_loss', min_delta=0.00, patience=30, verbose=False, mode='min')\n",
    "trainer = pl.Trainer(max_epochs=t_params['epochs'], auto_lr_find=False, gpus=1, amp_level='O1', precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/kev/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | AttentiveNP | 1 M   \n",
      "INFO:lightning:\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | AttentiveNP | 1 M   \n",
      "/home/kev/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: DeprecationWarning: Method `validation_end` was deprecated in v0.7 and will be removed in v1.0. Use `validation_epoch_end` instead.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/kev/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72dd0a069f3438f9d4be56426db704f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
