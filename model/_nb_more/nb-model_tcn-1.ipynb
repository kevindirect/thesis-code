{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb-model_tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     47\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_DIR, NestedDefaultDict, str_now, is_valid, isnt, makedir_if_not_exists, load_df, load_json, dump_json, rectify_json\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, INTERVAL_YEARS, OPTUNA_DB_FNAME, OPTUNA_N_TRIALS, OPTUNA_TIMEOUT_HOURS, INTRADAY_LEN\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PYTORCH_ACT1D_LIST, PYTORCH_INIT_LIST\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import sep\n",
    "from os.path import dirname, realpath, exists\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from itertools import permutations\n",
    "import logging\n",
    "\n",
    "def get_cwd(fname, subdir, crunch_dir=realpath(Path.home()) +sep +'crunch' +sep):\n",
    "    \"\"\"\n",
    "    Convenience function to make a directory string for the current file based on inputs.\n",
    "    Jupyter Notebook in Anaconda invokes the Python interpreter in Anaconda's subdirectory\n",
    "    which is why changing sys.argv[0] is necessary. In the future a better way to do this\n",
    "    should be preferred..\n",
    "    \"\"\"\n",
    "    return crunch_dir +subdir +fname\n",
    "\n",
    "def fix_path(cwd):\n",
    "    \"\"\"\n",
    "    Convenience function to fix argv and python path so that jupyter notebook can run the same as\n",
    "    any script in crunch.\n",
    "    \"\"\"\n",
    "    sys.argv[0] = cwd\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "fname = 'nb-model_tcn-1.ipynb'\n",
    "dir_name = 'model'\n",
    "fix_path(get_cwd(fname, dir_name +sep))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from verification.batch_norm import BatchNormVerificationCallback\n",
    "from verification.batch_gradient import BatchGradientVerificationCallback\n",
    "# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "from common_util import MODEL_DIR, NestedDefaultDict, str_now, is_valid, isnt, makedir_if_not_exists, load_df, load_json, dump_json, rectify_json\n",
    "from model.common import ASSETS, INTERVAL_YEARS, OPTUNA_DB_FNAME, OPTUNA_N_TRIALS, OPTUNA_TIMEOUT_HOURS, INTRADAY_LEN\n",
    "from model.common import PYTORCH_ACT1D_LIST, PYTORCH_INIT_LIST\n",
    "from model.xg_util import get_xg_feature_dfs, get_xg_label_target_dfs, get_hardcoded_feature_dfs, get_hardcoded_label_target_dfs\n",
    "from model.pl_xgdm import XGDataModule\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_trial(asset_name, fdata_name, ldata_name):\n",
    "    max_epochs = None\n",
    "    min_epochs = 20\n",
    "    model_name = 'stcn'\n",
    "    monitor = 'val_accuracy'\n",
    "    num_classes = 2\n",
    "\n",
    "    optimize_dir = {\n",
    "        'val_loss': 'minimize'\n",
    "    }.get(monitor, 'maximize')\n",
    "\n",
    "    # model options: stcn, anp\n",
    "    if (model_name in ('stcn', 'StackedTCN', 'GenericModel_StackedTCN')):\n",
    "        from model.pl_generic import GenericModel\n",
    "        from model.model_util import StackedTCN\n",
    "        pl_model_fn, pt_model_fn = GenericModel, StackedTCN\n",
    "    elif (model_name in ('anp', 'AttentiveNP', 'NPModel_AttentiveNP')):\n",
    "        from model.pl_np import NPModel\n",
    "        from model.np_util import AttentiveNP\n",
    "        pl_model_fn, pt_model_fn = NPModel, AttentiveNP\n",
    "    elif (model_name in ('ffn', 'FFN', 'GenericModel_FNN')):\n",
    "        from model.pl_generic import GenericModel\n",
    "        from model.model_util import FFN\n",
    "        pl_model_fn, pt_model_fn = GenericModel, FFN\n",
    "    model_name = f'{pl_model_fn.__name__}_{pt_model_fn.__name__}'\n",
    "\n",
    "    m_params = pt_model_fn.suggest_params(trial=None, num_classes=num_classes, add_ob=True)\n",
    "    t_params = pl_model_fn.suggest_params(trial=None, num_classes=num_classes)\n",
    "    logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "    print('cuda status: {}'.format('âœ“' if (torch.cuda.is_available()) else 'ðŸž©'))\n",
    "\n",
    "    m_params['size'] = 1\n",
    "    m_params['depth'] = 1\n",
    "    m_params['kernel_sizes'] = 8\n",
    "    m_params['input_dropout'] = 0\n",
    "    m_params['output_dropout'] = 0\n",
    "    m_params['global_dropout'] = 0\n",
    "    m_params['block_act'] ='relu'\n",
    "    m_params['block_init'] = 'kaiming_uniform'\n",
    "    m_params['out_act'] = 'relu'\n",
    "    m_params['out_init'] = 'kaiming_uniform'\n",
    "    m_params['ob_act'] = 'relu'\n",
    "    m_params['ob_init'] = 'kaiming_uniform'\n",
    "    m_params['ob_out_shapes'] = [2]\n",
    "    m_params['pad_mode'] = 'full'\n",
    "\n",
    "    class_weights = torch.zeros(num_classes, dtype=torch.float32, device='cpu', requires_grad=False)\n",
    "    class_weights[0] = .52\n",
    "    class_weights[1] = 1-class_weights[0]\n",
    "    opt = {\n",
    "        'name': 'adam',\n",
    "        'kwargs': {\n",
    "            'lr': 1e-3,\n",
    "            'betas': (0.9, 0.999),\n",
    "            'weight_decay': 0,\n",
    "            'amsgrad': False\n",
    "        }\n",
    "    }\n",
    "    t_params['loss'] = 'ce'\n",
    "    t_params['class_weights'] = None #class_weights\n",
    "    t_params['train_shuffle'] = False\n",
    "    t_params['batch_size'] = 64\n",
    "    t_params['epochs'] = 100\n",
    "    t_params['opt'] = opt\n",
    "    t_params['window_size'] = 1\n",
    "\n",
    "    dm = XGDataModule(t_params, asset_name, fdata_name, ldata_name, fret=None, overwrite_cache=False)\n",
    "    dm.prepare_data()\n",
    "    dm.setup()\n",
    "    trial_time = str_now().replace(' ', '_').replace(':', '-')\n",
    "    study_dir = MODEL_DIR +sep.join(['log', model_name, asset_name, dm.name]) +sep\n",
    "    makedir_if_not_exists(study_dir)\n",
    "    trial_dir = f'{study_dir}{trial_time}{sep}'\n",
    "    bench_fname = 'benchmark.json'\n",
    "    if (not exists('{study_dir}{bench_fname}')):\n",
    "        bench = dm.get_benchmarks()\n",
    "        dump_json(bench, bench_fname, study_dir)\n",
    "    print('trial dir:', trial_dir)\n",
    "    csv_log = pl.loggers.csv_logs.CSVLogger(trial_dir, name='', version='')\n",
    "    tb_log = pl.loggers.tensorboard.TensorBoardLogger(trial_dir, name='', version='', log_graph=False)\n",
    "    chk_callback = pl.callbacks.ModelCheckpoint(f'{trial_dir}chk{sep}', monitor=monitor, mode=optimize_dir[:3])\n",
    "    ver_callbacks = (BatchNormVerificationCallback(), BatchGradientVerificationCallback())\n",
    "    mdl = pl_model_fn(pt_model_fn, m_params, t_params, dm.fobs)\n",
    "\n",
    "    makedir_if_not_exists(trial_dir)\n",
    "    dump_json(rectify_json(m_params), 'params_m.json', trial_dir)\n",
    "    dump_json(rectify_json(t_params), 'params_t.json', trial_dir)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs or t_params['epochs'],\n",
    "            min_epochs=min_epochs, logger=[csv_log, tb_log],\n",
    "            callbacks=[chk_callback, *ver_callbacks],\n",
    "            limit_val_batches=1.0, gradient_clip_val=0., #track_grad_norm=2,\n",
    "            auto_lr_find=False, amp_level='O1', precision=16,\n",
    "            default_root_dir=trial_dir, weights_summary=None,\n",
    "            #overfit_batches=1,\n",
    "            gpus=-1 if (torch.cuda.is_available()) else None)\n",
    "    trainer.fit(mdl, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perms = list('hpomzug')\n",
    "# n = 10\n",
    "\n",
    "# for asset_name in ASSETS:\n",
    "#     for src in ('pba', 'vol', 'buzz'):\n",
    "#         for c in perms:\n",
    "#             for i in range(n):\n",
    "#                 run_trial(asset_name, f'h_{src}_{c}', 'ddir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = ('pba', 'vol', 'buzz')\n",
    "perms = [''.join(c) for c in permutations('moz')]\n",
    "n = 10\n",
    "\n",
    "for asset_name in ASSETS:\n",
    "    print(asset_name)\n",
    "    for src in srcs:\n",
    "        print(src)\n",
    "        for c in perms:\n",
    "            print(c)\n",
    "            for i in range(n):\n",
    "                run_trial(asset_name, f'h_{src}_{c}', 'ddir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
